{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build UHE-daily Zarr\n",
    "Inspired by this [great blog and repo](https://earthmover.io/blog/serverless-datacube-pipeline/#What-Could-be-Improved).\n",
    "\n",
    "## How this works\n",
    "The input data is about > 12k tifs. Instead of using Xarray's open_mfdataset + rasterio, this approach creates a Zarr store by:\n",
    "1. Create a 'skeleton' or 'template' of what the structure of the ending Zarr store should look like and write it to cloud storage.\n",
    "2. Insert slices into the template to fill out the Zarr store. This was done via coiled functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import coiled\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to create input dataset urls and parse Xarray datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_wget_strings(start_year: int, end_year: int) -> list:\n",
    "    \"\"\"\n",
    "    Access the UHE-daily gridded data product that formed the basis for\n",
    "    Tuholske et al (2021).\n",
    "    \"\"\"\n",
    "    daterange = pd.date_range(f\"{start_year}-01-01\", f\"{end_year}-12-31\")\n",
    "    return [\n",
    "        f\"https://data.chc.ucsb.edu/people/cascade/UHE-daily/wbgtmax/{date.strftime('%Y')}/wbgtmax.{date.strftime('%Y.%m.%d')}.tif\"\n",
    "        for date in daterange\n",
    "    ]\n",
    "\n",
    "\n",
    "def parse_ds(ds: xr.Dataset) -> xr.Dataset:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    ds = (\n",
    "        ds.expand_dims(\n",
    "            time=[np.datetime64(\"-\".join(ds.encoding[\"source\"].split(\".\")[-4:-1]))]\n",
    "        )\n",
    "        .squeeze(dim=[\"band\"], drop=True)\n",
    "        .drop(\"spatial_ref\")\n",
    "        .rename({\"band_data\": \"WBGT\", \"x\": \"lon\", \"y\": \"lat\"})\n",
    "        .sortby(\"lat\")\n",
    "    )\n",
    "    ds = ds.chunk({\"time\": 1, \"lat\": 2600, \"lon\": 7200})\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open a single dataset and use it to create the template Zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = 1983\n",
    "end_year = 2016\n",
    "uhe_urls = gen_wget_strings(start_year, end_year)\n",
    "first_url = uhe_urls[0]\n",
    "\n",
    "ds = xr.open_dataset(first_url, engine=\"rasterio\", chunks={})\n",
    "ds = parse_ds(ds)\n",
    "\n",
    "\n",
    "daterange = pd.date_range(f\"{start_year}-01-01\", f\"{end_year}-12-31\")\n",
    "\n",
    "template = (\n",
    "    ds.pipe(xr.zeros_like)\n",
    "    .isel(time=0, drop=True)\n",
    "    .expand_dims(time=daterange)\n",
    "    .chunk({\"time\": 1, \"lat\": 2600, \"lon\": 7200})\n",
    ")\n",
    "template.to_zarr(\n",
    "    \"s3://carbonplan-climate-impacts/extreme-heat-extension/v1.0/inputs/uhe_daily.zarr\",\n",
    "    zarr_format=3,\n",
    "    consolidated=False,\n",
    "    compute=False,\n",
    "    mode=\"w\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill the Zarr template with slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@coiled.function(vm_type=\"m7g.medium\", region=\"us-west-2\", n_workers=1)\n",
    "def delayed_write_region(url: str):\n",
    "    ds = xr.open_dataset(url, engine=\"rasterio\")\n",
    "    ds = parse_ds(ds)\n",
    "    ds.to_zarr(\n",
    "        \"s3://carbonplan-climate-impacts/extreme-heat-extension/v1.0/inputs/uhe_daily.zarr\",\n",
    "        zarr_format=3,\n",
    "        region=\"auto\",\n",
    "        compute=True,\n",
    "        consolidated=False,\n",
    "    )\n",
    "    return (\"success\", url)\n",
    "\n",
    "\n",
    "def run_coiled() -> list:\n",
    "    results = list(\n",
    "        tqdm(\n",
    "            delayed_write_region.map(uhe_urls, retries=5),\n",
    "            total=len(uhe_urls),\n",
    "            desc=\"Jobs Completed\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "results_list = run_coiled()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the final Zarr store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mds = xr.open_zarr(\n",
    "    \"s3://carbonplan-climate-impacts/extreme-heat-extension/v1.0/inputs/uhe_daily.zarr\",\n",
    "    chunks={},\n",
    ")\n",
    "mds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uhe_daily_recipe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
